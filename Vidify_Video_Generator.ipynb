{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Vidify: AI Story Video Generator:-\n",
        "This notebook contains the complete code for the Vidify video generation pipeline. It uses a multi-stage AI process to transform a user's short story into a complete, narrated video with dynamic scenes and selectable art styles.\n",
        "\n",
        "How to Run:-\n",
        "Add Your API Keys: On the left sidebar, click the key icon to open the Secrets Manager. You must add the following three secrets for the application to work:\n",
        "\n",
        "GOOGLE_API_KEY\n",
        "\n",
        "REPLICATE_API_TOKEN\n",
        "\n",
        "AZURE_SPEECH_KEY\n",
        "\n",
        "AZURE_SPEECH_REGION\n",
        "\n",
        "Run the Code: Once your keys are set, you can run the code cell below. The script will:\n",
        "\n",
        "Install all necessary libraries.\n",
        "\n",
        "Define the core AI functions.\n",
        "\n",
        "Run a test with a sample story.\n",
        "\n",
        "Find Your Video: The final .mp4 video file will be generated and saved in the Colab file explorer, also on the left sidebar. You can download it from there.\n",
        "\n",
        "Note: The full process can take several minutes to complete."
      ],
      "metadata": {
        "id": "5IEvZdSMbOrr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlUUGIHLQJMG"
      },
      "outputs": [],
      "source": [
        "!pip install azure-cognitiveservices-speech\n",
        "!apt-get install -y ffmpeg\n",
        "!apt-get update && apt-get install -y imagemagick\n",
        "print(\"Libraries installed!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U6WWcBQVs1P"
      },
      "outputs": [],
      "source": [
        "#change the policy for file paths from no access to read/write access in ImageMagick\n",
        "!sed -i 's/<policy domain=\"path\" rights=\"none\" pattern=\"@\\*\"\\/>/<policy domain=\"path\" rights=\"read|write\" pattern=\"@\\*\"\\/>/g' /etc/ImageMagick-6/policy.xml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oUqPJLNj1E4"
      },
      "outputs": [],
      "source": [
        "STYLE_PRESETS = {\n",
        "    \"anime\": \"anime style, vibrant colors, Studio Ghibli aesthetic\",\n",
        "    \"realistic\": \"photorealistic, 4k, cinematic, sharp focus, detailed, professional photography\",\n",
        "    \"fantasy_art\": \"fantasy digital painting, epic, vibrant, detailed, concept art, artstation\",\n",
        "    \"comic_book\": \"graphic novel illustration, comic book art, bold lines, cel shading, ink drawing\",\n",
        "    \"cyberpunk\": \"cyberpunk art, neon-drenched, Blade Runner aesthetic, futuristic, high-tech\",\n",
        "    \"watercolor\": \"vibrant watercolor painting, soft wash, beautiful, detailed, paper texture\",\n",
        "    \"vintage_film\": \"1950s black and white film, vintage, film grain, noir style, cinematic lighting\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ndii4XBQq2G"
      },
      "outputs": [],
      "source": [
        "REPLICATE_API_TOKEN = \"ENTER API\" # @param\n",
        "AZURE_SPEECH_KEY = \"ENTER API\" # @param\n",
        "GOOGLE_API_KEY = \"ENTER API\" # @param\n",
        "AZURE_SPEECH_REGION = \"ENTER REGION (EX: eastus)\" # @param\n",
        "\n",
        "import os\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN\n",
        "os.environ[\"AZURE_SPEECH_KEY\"] = AZURE_SPEECH_KEY\n",
        "os.environ[\"AZURE_SPEECH_REGION\"] = AZURE_SPEECH_REGION\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "print(\"APIs configured!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbA3uHOWRQ1Z"
      },
      "outputs": [],
      "source": [
        "!pip install -q replicate moviepy python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrrNFsroQ5aR"
      },
      "outputs": [],
      "source": [
        "from moviepy.editor import *\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "import replicate\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Create speechConfig and speechsynthesizer\n",
        "speech_config = speechsdk.SpeechConfig(\n",
        "    subscription=os.environ.get(\"AZURE_SPEECH_KEY\"),\n",
        "    region=os.environ.get(\"AZURE_SPEECH_REGION\")\n",
        ")\n",
        "# Select a voice name\n",
        "speech_config.speech_synthesis_voice_name = \"en-US-JennyNeural\"\n",
        "speech_synthesizer = speechsdk.SpeechSynthesizer(\n",
        "    speech_config=speech_config,\n",
        "    audio_config=None\n",
        ")\n",
        "\n",
        "\n",
        "def generate_video_from_script(visual_script, add_subtitles=False, aspect_ratio=\"1:1\"):\n",
        "    print(\"Video Generation Started...\")\n",
        "    if add_subtitles:\n",
        "        print(\"   - Subtitle option is ON\")\n",
        "    print(f\"   - Aspect ratio is set to {aspect_ratio}\")\n",
        "\n",
        "    if aspect_ratio == \"9:16\":\n",
        "        width, height = 896, 1536\n",
        "    elif aspect_ratio == \"16:9\":\n",
        "        width, height = 1344, 768\n",
        "    else:\n",
        "        width, height = 1024, 1024\n",
        "\n",
        "    #  Generate pics and audio\n",
        "    for i, scene in enumerate(visual_script):\n",
        "        image_prompt = scene['image_prompt']\n",
        "        negative_prompt = scene['negative_prompt']\n",
        "        print(f\"Generating image for scene {i+1}/{len(visual_script)}...\")\n",
        "        output = replicate.run(\n",
        "            \"stability-ai/sdxl:c221b2b8ef527988fb59bf24a8b97c4561f1c671f73bd389f866bfb27c061316\",\n",
        "            input={\n",
        "                \"prompt\": image_prompt,\n",
        "                \"negative_prompt\": negative_prompt,\n",
        "                \"num_inference_steps\": 25,\n",
        "                \"width\": width,\n",
        "                \"height\": height\n",
        "            }\n",
        "        )\n",
        "        urllib.request.urlretrieve(str(output[0]), f\"image_{i}.png\")\n",
        "\n",
        "        audio_text = scene['audio_text']\n",
        "        print(f\"Generating audio for scene {i+1}/{len(visual_script)}...\")\n",
        "\n",
        "        result = speech_synthesizer.speak_text_async(audio_text).get()\n",
        "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
        "            with open(f\"audio_{i}.mp3\", \"wb\") as f:\n",
        "                f.write(result.audio_data)\n",
        "        else:\n",
        "            cancellation_details = result.cancellation_details\n",
        "            print(f\"Error generating audio: {cancellation_details.reason}\")\n",
        "            if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
        "                print(f\"Error details: {cancellation_details.error_details}\")\n",
        "\n",
        "    #Assemble video\n",
        "    print(\"\\nAll assets generated.rendering the final video(/)\")\n",
        "    clips = []\n",
        "    for i, scene in enumerate(visual_script):\n",
        "        audio_clip = AudioFileClip(f\"audio_{i}.mp3\")\n",
        "        image_clip = ImageClip(f\"image_{i}.png\").set_duration(audio_clip.duration)\n",
        "\n",
        "        if add_subtitles:\n",
        "            subtitle_text = scene['audio_text']\n",
        "            text_clip = TextClip(\n",
        "                subtitle_text,\n",
        "                fontsize=45,\n",
        "                color='white',\n",
        "                font='Arial-Bold',\n",
        "                size=(image_clip.w * 0.9, None),\n",
        "                method='caption'\n",
        "            )\n",
        "            text_clip = text_clip.set_position(('center', 'bottom')).set_duration(image_clip.duration)\n",
        "            video_clip = CompositeVideoClip([image_clip, text_clip])\n",
        "        else:\n",
        "            video_clip = image_clip\n",
        "\n",
        "        video_clip = video_clip.set_audio(audio_clip)\n",
        "        clips.append(video_clip)\n",
        "\n",
        "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
        "    output_filename = f\"final_video_{aspect_ratio.replace(':', 'x')}.mp4\"\n",
        "    final_video.write_videofile(output_filename, fps=24, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "    print(f\"Video generated! File saved as '{output_filename}'\")\n",
        "    return output_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ5EjiS_0aIT"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "def generate_visual_script_v2(story, style=\"anime style, vibrant colors, Studio Ghibli aesthetic\"):\n",
        "    api_key = os.environ.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=api_key)\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "    system_prompt = f\"\"\"You are a master visual director and scriptwriter for an AI video generation pipeline. Your task is to take a story and transform it into a highly detailed, consistent, scene-by-scene script.\n",
        "\n",
        "    Your output must be a single, valid JSON list. Each object in the list must have two keys: `audio_text` and `image_prompt`.\n",
        "\n",
        "    Here are the strict rules you must follow for every scene:\n",
        "\n",
        "    #### **I. General Visual and Character Consistency**\n",
        "\n",
        "    1.  **Core Aesthetic**: Every `image_prompt` must start with the core aesthetic: **\"{style}.\"**\n",
        "    2.  **Character Registry**: When a character is first introduced, create a detailed description for them based on the text. If the text provides no details, invent a plausible appearance. You must re-use this EXACT full description every time the character appears.\n",
        "    3.  **Background Registry**: Follow the same rule for settings. Describe them in detail once and re-use that full description.\n",
        "    4.  **Re-Use Full Descriptions**: For every prompt, every character and setting present MUST be described using their full registry details.\n",
        "\n",
        "    #### **II. Story Breakdown and Scene Management**\n",
        "\n",
        "    1.  **Split Complex Actions**: If a sentence has multiple distinct actions, break it into separate scenes.\n",
        "    2.  **Combine Filler Sentences**: If a sentence is an emotional detail or a non-visual thought, combine its text with the previous visual scene's `audio_text`.\n",
        "    3.  **Prioritize Focus and Action**: Place the main character and their primary action at the beginning of the `image_prompt`. For example: \"Leo cautiously approaching Cora...\". **Crucially, the action described in the `image_prompt` must ONLY be what is described in that same scene's `audio_text`. Do not include actions or reactions from future sentences.**\n",
        "    4.  **Detail Background Characters**: Always include full descriptions for characters in the background.\n",
        "    5.  **Quality Enhancers**: Always append the following to the very end of every `image_prompt`: \", highly detailed, cinematic lighting, masterpiece, sharp focus, intricate details.\"\n",
        "    6.  **Dynamic Negative Prompt**: You must generate a `negative_prompt` for every scene. The default should be \"blurry, lowres, bad anatomy, worst quality\". **Crucially, if the scene contains only ONE person, you MUST add \"duplicate, cloned, multiple people\" to the negative_prompt.** If the scene explicitly describes more than one person, you must NOT add these words.\n",
        "    7.  **Sentence Mapping Requirement**: Include a `sentence_ids` field listing the original sentence IDs used for the `audio_text`.\n",
        "\n",
        "    #### **III. Example of Perfect Output**\n",
        "\n",
        "    EXAMPLE 1:\n",
        "    **Original Story**: \"As the sun dipped below the cherry blossom trees, Yuki stood alone at the train station. She felt a profound sense of loneliness. Then, Haru appeared, soaked but smiling. He was a young man with a slender build.\"\n",
        "\n",
        "    **Correct JSON Output**:\n",
        "        [\n",
        "      {{\n",
        "        \"audio_text\": \"As the sun dipped below the cherry blossom trees, Yuki stood alone at the train station. She felt a profound sense of loneliness.\",\n",
        "        \"image_prompt\": \"{style}, Yuki, a young woman with a melancholic expression, standing alone at a bustling train station at sunset, with cherry blossom trees in the background and soft, warm lighting, highly detailed, cinematic lighting, masterpiece, sharp focus, intricate details.\",\n",
        "        \"sentence_ids\": [\"s1\", \"s2\"]\n",
        "      }},\n",
        "      {{\n",
        "        \"audio_text\": \"Then, Haru appeared, soaked but smiling. He was a young man with a slender build.\",\n",
        "        \"image_prompt\": \"{style}, Haru, a young man with a slender build, soaked from the rain but smiling warmly, appearing in the distance at a bustling train station at sunset, with cherry blossom trees in the background, Yuki, a young woman with a melancholic expression, standing in the background with a surprised look, highly detailed, cinematic lighting, masterpiece, sharp focus, intricate details.\",\n",
        "        \"sentence_ids\": [\"s3\", \"s4\"]\n",
        "      }}\n",
        "    ]\n",
        "    \"\"\"\n",
        "\n",
        "    response = model.generate_content(f\"Story: {story}\\n\\n{system_prompt}\")\n",
        "\n",
        "    try:\n",
        "        json_start = response.text.find('[')\n",
        "        json_end = response.text.rfind(']')\n",
        "        if json_start != -1 and json_end != -1:\n",
        "            json_string = response.text[json_start : json_end + 1]\n",
        "            return json.loads(json_string)\n",
        "        else:\n",
        "            raise ValueError(\"Could not find valid JSON content in API response.\")\n",
        "    except (json.JSONDecodeError, ValueError) as e:\n",
        "        print(f\"Error parsing JSON: {e}\")\n",
        "        print(\"Raw API response:\")\n",
        "        print(response.text)\n",
        "        raise\n",
        "\n",
        "\n",
        "    response = model.generate_content(f\"Story: {story}\\n\\n{system_prompt}\")\n",
        "\n",
        "    try:\n",
        "        json_start = response.text.find('[')\n",
        "        json_end = response.text.rfind(']')\n",
        "        if json_start != -1 and json_end != -1:\n",
        "            json_string = response.text[json_start : json_end + 1]\n",
        "            return json.loads(json_string)\n",
        "        else:\n",
        "            raise ValueError(\"Could not find valid JSON content in API response.\")\n",
        "    except (json.JSONDecodeError, ValueError) as e:\n",
        "        print(f\"Error parsing JSON: {e}\")\n",
        "        print(\"Raw API response:\")\n",
        "        print(response.text)\n",
        "        raise\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84RbfzkEYQQ2"
      },
      "outputs": [],
      "source": [
        "#overall workflow\n",
        "style_choice = \"anime\"  #you can choose your video style, default is anime\n",
        "\n",
        "# give your story here\n",
        "story_text = \"\"\"\n",
        "Elara, a young woman with braided brown hair and a simple leather tunic, followed the ancient map. It led her to a hidden cave behind a waterfall. Inside, an old man with a long white beard sat by a fire. He looked up and pointed a gnarled finger towards a glowing crystal resting on a stone pedestal.\n",
        "\"\"\"\n",
        "\n",
        "full_style_prompt = STYLE_PRESETS.get(style_choice, STYLE_PRESETS[\"anime\"])\n",
        "\n",
        "print(f\"Calling creative director with style: '{style_choice}'\")\n",
        "visual_script = generate_visual_script_v2(\n",
        "    story_text,\n",
        "    style=full_style_prompt\n",
        ")\n",
        "\n",
        "print(\"\\nScript generated!!\")\n",
        "\n",
        "print(\"\\nSending script to production\")\n",
        "video_path = generate_video_from_script(\n",
        "    visual_script,\n",
        "    add_subtitles=True,\n",
        "    aspect_ratio=\"16:9\"\n",
        ")\n",
        "\n",
        "print(f\"\\nYour video is ready at: {video_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading the final video\n",
        "from google.colab import files\n",
        "print(\"ðŸš€ Preparing video for download...\")\n",
        "files.download(video_path)"
      ],
      "metadata": {
        "id": "JgBfTJgHdQbr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
